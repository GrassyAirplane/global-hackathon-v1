version: '3'
services:
  frontend:
    restart: always
    ports:
      - "3000:3000"
    build: 
      context: ./frontend
      dockerfile: ./Dockerfile  

  backend:
    restart: always
    ports:
      - "5000:5000"
    build:
      context: ./backend
      dockerfile: ./Dockerfile
    command: npm run start-dev

models: 
  llm:
    model: ai/llama3.2:1B-Q8_0
